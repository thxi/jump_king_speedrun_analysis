{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c462bc7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:31:34.176159Z",
     "start_time": "2021-05-15T09:31:33.499086Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1530ab9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:31:34.190303Z",
     "start_time": "2021-05-15T09:31:34.177256Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261cc434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:31:34.212818Z",
     "start_time": "2021-05-15T09:31:34.191659Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6955002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:40:38.914855Z",
     "start_time": "2021-05-15T09:40:38.894311Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.utils import crop_margins, dist, get_game_margins, open_video\n",
    "from utils.detect_king import get_king_positions\n",
    "from utils.map_frames import map_frames\n",
    "from utils.screen_to_frame import get_screen_to_frame\n",
    "from utils.heatmap import make_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcc6157",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T08:13:21.230111Z",
     "start_time": "2021-05-15T08:13:21.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "screen_to_frame = pickle.load(open(\"data/screen_to_frame.p\", \"rb\"))\n",
    "# screen_to_frame = np.array([v.ravel() for v in screen_to_frame.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4398cf18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T12:23:07.229673Z",
     "start_time": "2021-05-14T12:23:01.692286Z"
    }
   },
   "outputs": [],
   "source": [
    "# check if all screens are present\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(16, 96))\n",
    "\n",
    "for i, s in tqdm(enumerate(screen_to_frame.values())):\n",
    "    plt.title(f\"Screen {i}\")\n",
    "    plt.subplot(22, 2, i + 1)\n",
    "    plt.imshow(s)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d3e979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b42b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a871664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:31:49.201942Z",
     "start_time": "2021-05-15T09:31:37.344012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting video start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a89ffd58704b669b6055c5762008d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video starts at frame 325\n",
      "mapping screens\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a9c79f4c2141499828d9ea13f2e4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10952 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done mapping screens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screen_to_frame = pickle.load(open(\"data/screen_to_frame.p\", \"rb\"))\n",
    "screen_to_frame = np.array([v.ravel() for v in screen_to_frame.values()])\n",
    "\n",
    "screen_to_frames, frame_to_screen = map_frames('data/speedrun_side.mp4',\n",
    "                                               screen_to_frame)\n",
    "\n",
    "cap = open_video('data/speedrun_side.mp4')\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2c7f2c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:32:05.389205Z",
     "start_time": "2021-05-15T09:31:49.203022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making screen to frame for video\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8cc2cbbda9495c89d53bdee60f3ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "screen_to_frame = get_screen_to_frame(cap, screen_to_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d69407f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:32:15.257308Z",
     "start_time": "2021-05-15T09:32:06.113275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting king's positions\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d90c5d3e5a40f1bf12fe8840d4e623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positions, screen_to_positions = get_king_positions(cap, screen_to_frames, screen_to_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d483278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:40:42.321271Z",
     "start_time": "2021-05-15T09:40:41.885442Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "heatmap = make_heatmap(screen_to_positions[i], screen_to_frame[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff5e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa7471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T08:14:48.251515Z",
     "start_time": "2021-05-15T08:14:48.237783Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f065b0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T08:14:49.532548Z",
     "start_time": "2021-05-15T08:14:49.514627Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096e22a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T08:14:50.153548Z",
     "start_time": "2021-05-15T08:14:50.122423Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_coord2view_coord(p, resolution, pmin, pmax):\n",
    "    dp = pmax - pmin\n",
    "    dv = (p - pmin) / dp * resolution\n",
    "    return dv\n",
    "\n",
    "def kNN2DDens(xv, yv, resolution, neighbours, dim=2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Create the tree\n",
    "    tree = cKDTree(np.array([xv, yv]).T)\n",
    "    # Find the closest nnmax-1 neighbors (first entry is the point itself)\n",
    "    grid = np.mgrid[0:resolution, 0:resolution].T.reshape(resolution**2, dim)\n",
    "    dists = tree.query(grid, neighbours)\n",
    "    # Inverse of the sum of distances to each grid point.\n",
    "    inv_sum_dists = 1. / dists[0].sum(1)\n",
    "\n",
    "    # Reshape\n",
    "    im = inv_sum_dists.reshape(resolution, resolution)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e63673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:23:11.407622Z",
     "start_time": "2021-05-15T09:23:11.382840Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "# remapping x with inverted y to w, h\n",
    "xmax = 60\n",
    "ymax = 44\n",
    "s2p = choices(screen_to_positions[0], k=1000)\n",
    "\n",
    "eps = np.random.normal(0, 1, size=1000)\n",
    "xs = np.array([i[0] for i in s2p])+eps\n",
    "eps = np.random.normal(0, 1, size=1000)\n",
    "ys = np.array([i[1] for i in s2p])+eps\n",
    "\n",
    "resolution = 250\n",
    "\n",
    "extent = [0, xmax, 0, ymax]\n",
    "xv = data_coord2view_coord(xs, resolution, extent[0], extent[1])\n",
    "yv = data_coord2view_coord(ys, resolution, extent[2], extent[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f714fe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:29:55.858041Z",
     "start_time": "2021-05-15T09:29:54.813646Z"
    }
   },
   "outputs": [],
   "source": [
    "for neighbours in [2]:\n",
    "    im = kNN2DDens(xv, yv, resolution, neighbours)\n",
    "    im = im*3000\n",
    "    im = np.clip(im, 0, 255).astype(np.uint8)\n",
    "    im = cv2.resize(im, (60, 44))\n",
    "    im = cv2.applyColorMap(im, cv2.COLORMAP_OCEAN)\n",
    "    im = imutils.resize(im, width=600)\n",
    "    im = cv2.GaussianBlur(im, (3,3), cv2.BORDER_DEFAULT)\n",
    "    cv2.imshow(\"frame\", im)\n",
    "    k = cv2.waitKey(int(2000)) & 0xFF\n",
    "    if k == ord('d'):\n",
    "        continue\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee77b49c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:29:56.501654Z",
     "start_time": "2021-05-15T09:29:56.489255Z"
    }
   },
   "outputs": [],
   "source": [
    "# im is bgr\n",
    "# im = cv2.cvtColor(im, cv2.COLOR_BGR2BGRA)\n",
    "im = cv2.resize(im, (600, 448))\n",
    "transp_mask = np.zeros_like(im).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0665bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:29:57.436154Z",
     "start_time": "2021-05-15T09:29:57.016552Z"
    }
   },
   "outputs": [],
   "source": [
    "# make background transparent\n",
    "for i in range(im.shape[0]):\n",
    "    for j in range(im.shape[1]):\n",
    "        if im[i][j][0] > 100:\n",
    "            transp_mask[i][j] = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631c282",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:30:09.781594Z",
     "start_time": "2021-05-15T09:30:09.765960Z"
    }
   },
   "outputs": [],
   "source": [
    "screen = screen_to_frame[0]\n",
    "heatmap = (transp_mask * im).astype(np.uint8) + ((1-transp_mask)*screen).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e5fe70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:30:16.691848Z",
     "start_time": "2021-05-15T09:30:16.480793Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd5c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b55cfd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T08:14:59.261016Z",
     "start_time": "2021-05-15T08:14:58.581794Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "for ax, neighbours in zip(axes.flatten(), [0, 2, 3, 4, 5]):\n",
    "\n",
    "    if neighbours == 0:\n",
    "        ax.plot(xs, ys, 'k.', markersize=5)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_title(\"Scatter Plot\")\n",
    "    else:\n",
    "\n",
    "        im = kNN2DDens(xv, yv, resolution, neighbours)\n",
    "        im = im*3000\n",
    "        im = np.clip(im, 0, 255)\n",
    "\n",
    "        ax.imshow(im, origin='lower', extent=extent, cmap=cm.Blues)\n",
    "        ax.set_title(\"Smoothing over %d neighbours\" % neighbours)\n",
    "    ax.set_xlim(extent[0], extent[1])\n",
    "    ax.set_ylim(extent[2], extent[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a376760d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b9b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa2908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e61f125",
   "metadata": {},
   "source": [
    "what am i going to present:\n",
    "\n",
    "width 60 of every video\n",
    "\n",
    "last screen corner case\n",
    "detect not continuous video corner case\n",
    "\n",
    "find global position of game on screen\n",
    "* detect the black line on top\n",
    "    \n",
    "* heatmap:\n",
    "    * array of coordinates\n",
    "    * for each frame\n",
    "    * screen = frame_to_screen(i) # offset?\n",
    "    * background = screen_to_frame[screen]\n",
    "    * detect king\n",
    "    * screen_to_positions = {screen: [[x, y]]}\n",
    "    * after:\n",
    "    * for each screen\n",
    "    * make a heatmap\n",
    "    * https://github.com/TobiasRoeddiger/GazePointHeatMap/blob/master/gazeheatplot.py\n",
    "    * https://stackoverflow.com/questions/2369492/generate-a-heatmap-in-matplotlib-using-a-scatter-data-set\n",
    "    * rgba to make transparent\n",
    "* statistical\n",
    "    * screentime\n",
    "    * number of falls (12-13 screens)\n",
    "    * number of total falls\n",
    "* corner cases\n",
    "    \n",
    "\n",
    "pipeline:\n",
    "* map_screens.py and screen_to_frame.py for static files\n",
    "* map_frames(filename, screen_to_frame)\n",
    "* for each screen in screen to frames detect motion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0554bf4",
   "metadata": {},
   "source": [
    "https://www.sicara.ai/blog/en/object-detection-template-matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d24151",
   "metadata": {},
   "source": [
    "https://debuggercafe.com/moving-object-detection-using-frame-differencing-with-opencv/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d87d72",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/build-a-motion-heatmap-videousing-opencv-with-python-fd806e8a2340"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eaba69",
   "metadata": {},
   "source": [
    "https://github.com/kjw0612/awesome-deep-vision#imagenet-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f647c81f",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1455fc26",
   "metadata": {},
   "source": [
    "https://www.pyimagesearch.com/2015/05/25/basic-motion-detection-and-tracking-with-python-and-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71db5bee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:22:44.524514Z",
     "start_time": "2021-05-14T07:22:44.484603Z"
    }
   },
   "outputs": [],
   "source": [
    "screen_to_frame = pickle.load(open(\"data/screen_to_frame.p\", \"rb\"))\n",
    "screen_to_frame = np.array([v.ravel() for v in screen_to_frame.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3377eb98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:22:58.804268Z",
     "start_time": "2021-05-14T07:22:46.696530Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "screen_to_frames, frame_to_screen = map_frames('data/speedrun_side.mp4', screen_to_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b3c00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:23:01.122748Z",
     "start_time": "2021-05-14T07:23:01.068420Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = open_video('data/speedrun_side.mp4')\n",
    "margin_left, margin_right = get_game_margins(cap)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7238301",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:25:55.427127Z",
     "start_time": "2021-05-14T07:25:42.961355Z"
    }
   },
   "outputs": [],
   "source": [
    "screen_to_positions = {}  # {screen: [[x, y]]}\n",
    "positions = []\n",
    "\n",
    "# some screens are badly initialized\n",
    "\n",
    "# if go back, then have to initialize screen_positions differently\n",
    "# if go back, then have to jump to next frame first\n",
    "for screen, frames in tqdm(screen_to_frames.items()):\n",
    "    if screen == 42:\n",
    "        continue\n",
    "    for (start, end) in frames:\n",
    "        n = end - start\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "        frames = []\n",
    "        for i in range(n):\n",
    "            ret, frame = cap.read()\n",
    "            if ret == False:\n",
    "                break\n",
    "\n",
    "            frame = crop_margins(frame, margin_left, margin_right)\n",
    "            frame = imutils.resize(frame, width=60)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            frames.append(frame)\n",
    "\n",
    "        avg_frame = np.mean(frames, axis=0).astype(np.uint8)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "        if len(positions) != 0:\n",
    "            x, _ = positions[-1]\n",
    "            screen_positions = [(x, frame.shape[0])]\n",
    "        else:\n",
    "            screen_positions = [(30, 40)]\n",
    "\n",
    "        for i in range(n):\n",
    "            ret, frame = cap.read()\n",
    "            if ret == False:\n",
    "                break\n",
    "\n",
    "            frame = crop_margins(frame, margin_left, margin_right)\n",
    "            frame = imutils.resize(frame, width=60)\n",
    "            orig_frame = frame.copy()\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            frame_diff = cv2.absdiff(avg_frame, frame)\n",
    "\n",
    "            # exponential smoothing\n",
    "            # TODO: if needed\n",
    "            # avg_frame = (0.3 * frame + 0.7 * avg_frame).astype(np.uint8)\n",
    "\n",
    "            ret, thres = cv2.threshold(frame_diff, 30, 255, cv2.THRESH_BINARY)\n",
    "            dilate_frame = cv2.dilate(thres, None, iterations=2)\n",
    "\n",
    "            contours, hierarchy = cv2.findContours(dilate_frame,\n",
    "                                                   cv2.RETR_EXTERNAL,\n",
    "                                                   cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            for contour in contours:\n",
    "                (x, y, w, h) = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(orig_frame, (x, y), (x + w, y + h), (0, 0, 255),\n",
    "                              1)\n",
    "\n",
    "            if len(contours) == 0:\n",
    "                screen_positions.append(screen_positions[-1])\n",
    "            elif len(contours) == 1:\n",
    "                (x, y, w, h) = cv2.boundingRect(contours[0])\n",
    "                if dist(screen_positions[-1], (x + w // 2, y + h // 2)) > 200:\n",
    "                    #print(\"more than 50\")\n",
    "                    # detected another object\n",
    "                    screen_positions.append(screen_positions[-1])\n",
    "                else:\n",
    "                    # print(\"her\")\n",
    "                    screen_positions.append((x + w // 2, y + h // 2))\n",
    "            else:\n",
    "                distances = []\n",
    "                for contour in contours:\n",
    "                    (x, y, w, h) = cv2.boundingRect(contour)\n",
    "                    distances.append(\n",
    "                        dist(screen_positions[-1], (x + w // 2, y + h // 2)))\n",
    "                pidx = np.argmin(distances)\n",
    "                (x, y, w, h) = cv2.boundingRect(contours[pidx])\n",
    "                screen_positions.append((x + w // 2, y + h // 2))\n",
    "\n",
    "            x, y = screen_positions[-1]\n",
    "\n",
    "        positions = positions + screen_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b135b7c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T13:05:09.818987Z",
     "start_time": "2021-05-12T13:05:09.789306Z"
    }
   },
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c216895",
   "metadata": {},
   "source": [
    "44x60 frame\n",
    "\n",
    "y x\n",
    "\n",
    "positions are\n",
    "x y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b46b682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:25:57.143476Z",
     "start_time": "2021-05-14T07:25:57.079794Z"
    }
   },
   "outputs": [],
   "source": [
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14820b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b368e1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab04fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:49:37.343847Z",
     "start_time": "2021-05-12T07:49:37.313636Z"
    }
   },
   "outputs": [],
   "source": [
    "king = cv2.imread('data/king.webp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d53f6ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:49:37.777914Z",
     "start_time": "2021-05-12T07:49:37.629284Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(king)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80821fea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:49:40.115632Z",
     "start_time": "2021-05-12T07:49:40.083851Z"
    }
   },
   "outputs": [],
   "source": [
    "king.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f41e255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d62675a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bd4b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
